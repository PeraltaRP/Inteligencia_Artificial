{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Codigo que atende  a atividade 2 de Inteligencia Artificial\n",
    "\n",
    "\n",
    "Alunos:Lucas Barbosa e  Pedro Peralta\n",
    "\n",
    "link para baixar a base de dados = https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/SRAG/2020/INFLUD-23-11-2020.csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Importação das bibliotecas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Relizar calculos numericos\n",
    "import pandas as pd #Ferramente  de analise de dados \n",
    "import seaborn as sns #Biblioteca que faz graficos estatisticos\n",
    "from sklearn import metrics #Constroi um relatorio com as metricas de classificação\n",
    "import matplotlib.pyplot as plt #Cria as figuras para as areas de plotagem\n",
    "from sklearn.neighbors import KNeighborsClassifier #Classificador que implementa a votação de K-vizinhos mais proximos\n",
    "from sklearn.linear_model import LogisticRegression #Classificador de regressão logistica\n",
    "from sklearn.model_selection import train_test_split #Divide  em vetores de treino e teste de forma aleatoria\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "source": [
    "Leitura do arquivo 'cru' que sera nossa base de dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('influ.csv', encoding='UTF-8', sep=';', usecols=['IMUNODEPRE','NU_IDADE_N','GARGANTA','SATURACAO','FEBRE','DESC_RESP','FATOR_RISC','CARDIOPATI','HEMATOLOGI'  \n",
    ",'SIND_DOWN','HEPATICA','ASMA','DIABETES' ,'NEUROLOGIC','PNEUMOPATI','RENAL','OBESIDADE'\n",
    ",'OUT_MORBI','UTI','SUPORT_VEN','CLASSI_FIN','EVOLUCAO'])"
   ]
  },
  {
   "source": [
    "Imprimindo o tipo de dados contidos em cada coluna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.dtypes"
   ]
  },
  {
   "source": [
    "Como dentro do arquivo a coluna FATOR_RISC esta no formato string e sem uma padronização, devemos converter as strings para minusculos e apos iremos  trocar o 'S' para 1 e 'N' para 2, simbolizando 1 para sim e 2 para nao"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['FATOR_RISC'] = dados['FATOR_RISC'].str.lower() #padronizando as strings para minusculo\n",
    "dados['FATOR_RISC'] = dados['FATOR_RISC'].map({'s':1,'n':2})\n",
    "dados['FATOR_RISC'].value_counts() #exibindo a quantidade de cada item que esta na coluna Fator_risco"
   ]
  },
  {
   "source": [
    "Agora iremos eliminar as linhas em que a CLASSI_FIN seja diferente de 5, casos com covid-19 confirmados são marcados como 5, para isso iremos criar uma especie de filtro"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_covid = dados['CLASSI_FIN'] == 5 \n",
    "dados = dados[filtro_covid]\n",
    "\n",
    "#para diminuir mais um pouco a quantidade de linhas do data frame iremos remover casos que evoluiram para morte mas por outro motivos eles sao demarcados como 3\n",
    "filtro_evolucao = dados['EVOLUCAO'] < 3\n",
    "dados = dados[filtro_evolucao]"
   ]
  },
  {
   "source": [
    "Um dados que ha muitas marcaçoes é a coluna SUPORT_VEN, onde temos 1 para ventilação invasiva 2 para ventilação nao invasiva e 3 para nao, iremos agrupar os dados 1 com 2 e mudar 3 para 2 assim a tabela obedece a regra 1 SIM e 2 NAO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['SUPORT_VEN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados[dados['SUPORT_VEN'] == 2] = 1\n",
    "dados[dados['SUPORT_VEN'] == 3] = 2\n",
    "dados['SUPORT_VEN'].value_counts()"
   ]
  },
  {
   "source": [
    "Verificando se ainda ha valores vazios dentro do Data Frame mostrando a quantidade de valores nulos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trocando os valores vazios por 2 e subistituindo os valores 9 'iginorados' para 2 tambem removendo esses valores do Data Frame\n",
    "dados.replace(9, 2, inplace=True) #determinando valores 'ignorados' para 2\n",
    "dados.replace(np.nan, inplace=True) #removendo do Data Frames valores vazios\n",
    "dados.dropna()\n",
    "dados.isnull().any()"
   ]
  },
  {
   "source": [
    "Apos termos apenas as linhas com casos confirmados de covid podemos eliminar esta coluna da base"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop(columns=['CLASSI_FIN'], axis=1, inplace=True)\n",
    "#salvando nosso modelo no disco \n",
    "dados.to_csv('modelo_covid.csv', index=False)"
   ]
  },
  {
   "source": [
    "Criando um grafico para determinar se ha muita correlação entra as tabelas e fazermos a Regressao Logistica "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dados.corr()\n",
    "sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(13,8))\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask, 1)] = True\n",
    "a = sns.heatmap(corr,mask=mask, annot=True, fmt='.2f')\n",
    "rotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "roty = a.set_yticklabels(a.get_yticklabels(), rotation=30)"
   ]
  },
  {
   "source": [
    "Agora iremos criar um modelo para treino e teste assin determinamos a sua acurracia"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#escolhendo as colunas que serao nosso valores de entrada para o modelo\n",
    "X = pd.DataFrame(columns=['FATOR_RISC','SIND_DOWN','HEPATICA','ASMA','NEUROLOGIC','PNEUMOPATI','RENAL','OUT_MORBI','UTI','SUPORT_VEN', 'SATURACAO'],data=dados)\n",
    "\n",
    "#verificando se existem valores faltantes nos dados\n",
    "X.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#escolhendo a coluna do Data Frame que sera a resposta do modelo\n",
    "y = pd.DataFrame(columns=['EVOLUCAO'], data = dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividindo os dados de teste e treino, selecionamos 30% para os teste e os 70 para treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizando os dados\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando se ha valores vazios dentro de X\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configurando e treinando o modelo de regreção\n",
    "logit =LogisticRegression(verbose=1, max_iter=1000)\n",
    "logit.fit(X_train,np.ravel(y_train,order='C'))\n",
    "y_pred=logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculando uma matriz de caonfusao, para a observar se o modelo esta correto\n",
    "cnf_matrix =  metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#código para melhor visualização da matriz de confusão\n",
    "cnf_matrix =  metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "#imprimindo a matriz de confusão\n",
    "plot_confusion_matrix(cnf_matrix, classes=['1','2'],\n",
    "                      title='Matriz de confusão não normalizada', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#métricas finais\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['1','2']))"
   ]
  },
  {
   "source": [
    "Utilizando a avaliaçao de comsulta com vizinhos proximos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 4)\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['SUPORT_VEN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando modelo com entrada definida \n",
    "#neste modelo o paciente tem todos os sintomas ativos\n",
    "X_new = np.array([[1,1,1,1,1,1,1,1,1,1,1]])\n",
    "X_new.shape\n",
    "prediction = knn.predict(X_new)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "source": [
    "Utilização da arvore de decisao para medir um score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividindo os dados de teste e treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "modelo = ExtraTreesClassifier()\n",
    "modelo.fit(X_train, y_train)\n",
    "resultado = modelo.score(X_test, y_test)\n",
    "print(\"Acurácia:\", resultado)"
   ]
  }
 ]
}